# WildRobot AMP - Phase 1 Rebase: Step 3 - Gentle Contact Reward (Warm-Start)
# Goal: Prevent catastrophic forgetting by adding minimal contact reward signal
# Strategy: Keep Phase 0 config entirely, add ONLY contact_alternation: 2.0
# Warm-start from: Step 2 checkpoint at 524,288 steps (Reward: 14.77, Vel: 0.239 m/s)

env:
  terrain: "flat"
  ctrl_dt: 0.02
  sim_dt: 0.002

  # Velocity command
  velocity_command_mode: "range"
  target_velocity: 0.7
  min_velocity: 0.5
  max_velocity: 1.0

  # Action filtering
  use_action_filter: true
  action_filter_alpha: 0.7

  # Phase signal (kept on; contact shaping uses later phases)
  use_phase_signal: true
  phase_period: 40
  num_phase_clocks: 2

  # Termination conditions
  min_height: 0.2
  max_height: 0.7

# Explicit set of tracked components for clearer diagnostics
# Added contact_alternation_ratio for Phase 1
tracked_reward_components:
  - tracking_exp_xy
  - tracking_lin_xy
  - tracking_exp_yaw
  - tracking_lin_yaw
  - forward_velocity_bonus
  - velocity_threshold_penalty
  - z_velocity
  - roll_pitch_velocity
  - roll_pitch_position
  - joint_velocity
  - joint_acceleration
  - action_rate
  - nominal_joint_position
  - joint_position_limit
  - joint_torque
  - mechanical_power
  - foot_contact
  - foot_sliding
  - existential
  - contact_alternation_ratio

# Reward weights - Phase 1 Step 3 (Gentle Contact Reward)
# Keep ALL Phase 0 weights, add ONLY contact_alternation
reward_weights:
  # Tracking kernel
  tracking_sigma: 0.25
  tracking_steepness: 3.0

  # Velocity threshold penalty
  velocity_threshold: 0.12
  velocity_threshold_penalty: 4.9
  velocity_threshold_penalty_decay_start: 0
  velocity_threshold_penalty_decay_steps: 0
  velocity_threshold_penalty_min_scale: 0.5

  # Velocity tracking
  tracking_exp_xy: 25.0
  tracking_lin_xy: 12.0
  tracking_exp_yaw: 5.0
  tracking_lin_yaw: 1.5

  # Direct forward velocity bonus
  forward_velocity_bonus: 51.0

  # Stability penalties
  z_velocity: 0.1
  roll_pitch_velocity: 0.008
  roll_pitch_position: 0.04

  # Smoothness penalties
  nominal_joint_position: 0.0
  joint_position_limit: 2.5
  joint_velocity: 0.0
  joint_acceleration: 1e-8
  action_rate: 0.001

  # Energy penalties
  joint_torque: 7e-8
  mechanical_power: 7e-6

  # Contact shaping
  foot_contact: 5.0
  foot_sliding: 0.5

  # NEW: Gentle contact alternation reward (Step 3 addition)
  # Weight: 2.0 (4% of forward_velocity_bonus 51.0)
  # Purpose: Provide learning signal to prevent drift, guide toward better gait
  contact_alternation: 2.0

  # Existential baseline & gating controls
  existential: 0.5
  tracking_gate_velocity: 0.05
  tracking_gate_scale: 0.45

training:
  num_timesteps: 2000000  # 2M steps for quick verification
  num_evals: 40
  episode_length: 600
  seed: 0

  # Warm-start from Step 2 checkpoint (524K steps)
  load_checkpoint: "saved_checkpoints/phase1_step2.pkl"

quick_verify:
  enabled: false
  num_timesteps: 10000
  num_evals: 2
  episode_length: 100
  num_envs: 128
  num_eval_envs: 16
  use_wandb: false
  render_videos: false
  save_checkpoints: false

ppo:
  num_envs: 512
  num_eval_envs: 64
  batch_size: 256
  unroll_length: 32
  num_minibatches: 16
  num_updates_per_batch: 4

  learning_rate: 0.0003
  entropy_cost: 0.01
  discounting: 0.99
  reward_scaling: 1.0

  max_grad_norm: 0.5
  clipping_epsilon: 0.2
  normalize_observations: true
  action_repeat: 1

network:
  policy_hidden_layers: [256, 256, 128]
  value_hidden_layers: [256, 256, 128]

logging:
  use_wandb: true
  wandb_project: "wildrobot-amp"
  wandb_entity: null
  wandb_tags: ["phase1", "contact", "rebase", "step3", "warmstart"]

rendering:
  render_videos: true
  render_height: 480
