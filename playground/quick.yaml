# Quick Training Configuration
# For fast prototyping and testing (smoke test - should complete in ~2 minutes)

env:
  terrain: "flat"
  ctrl_dt: 0.02
  sim_dt: 0.002

training:
  num_timesteps: 100000       # 100K steps (VERY fast smoke test)
  num_evals: 2                # Just 2 evals to verify it works
  episode_length: 200         # Shorter episodes
  seed: 0

ppo:
  num_envs: 256               # Fewer envs for faster compilation (must divide batch_size * num_minibatches)
  num_eval_envs: 32           # Fewer eval envs
  batch_size: 128             # Smaller batch (128 * 2 = 256, divisible by 256 envs)
  unroll_length: 5            # Shorter unrolls
  num_minibatches: 2          # Fewer minibatches
  num_updates_per_batch: 2    # Fewer updates

  learning_rate: 0.0003
  entropy_cost: 0.01
  discounting: 0.97
  reward_scaling: 0.1

  max_grad_norm: 1.0
  clipping_epsilon: 0.2
  normalize_observations: true
  action_repeat: 1

network:
  policy_hidden_layers: [128, 128]       # Smaller network
  value_hidden_layers: [128, 128]

logging:
  use_wandb: false            # Disable W&B for quick testing
  wandb_project: "wildrobot"
  wandb_entity: null

rendering:
  render_videos: false        # Disable videos for quick testing (very slow!)
  render_height: 480
  render_width: 640

checkpointing:
  save_interval: 1000000
  keep_checkpoints: 3
