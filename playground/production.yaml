# Production Training Configuration
# Optimized for best performance with large GPU

env:
  terrain: "flat"
  ctrl_dt: 0.02
  sim_dt: 0.002

training:
  num_timesteps: 50000000     # 50M steps
  num_evals: 20
  episode_length: 1000
  seed: 42

ppo:
  num_envs: 4096              # Maximum parallelization
  num_eval_envs: 256
  batch_size: 1024
  unroll_length: 10
  num_minibatches: 16
  num_updates_per_batch: 8

  learning_rate: 0.0003
  entropy_cost: 0.01
  discounting: 0.97
  reward_scaling: 0.1

  max_grad_norm: 1.0
  clipping_epsilon: 0.2
  normalize_observations: true
  action_repeat: 1

network:
  policy_hidden_layers: [512, 512, 256]  # Larger network
  value_hidden_layers: [512, 512, 256]

logging:
  use_wandb: true             # Enable W&B logging
  wandb_project: "wildrobot"
  wandb_entity: null

rendering:
  render_videos: true
  num_videos: 5
  render_height: 720
  render_width: 1280

checkpointing:
  save_interval: 500000       # Save more frequently
  keep_checkpoints: 10
