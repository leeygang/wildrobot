# =============================================================================
# WildRobot PPO Standing Config (v0.12.2)
# =============================================================================
# Stage 1: Standing robustness with strong push disturbances (No AMP)
#
# Goal: Robot maintains balance under stronger lateral pushes.
# Exit Criteria: Fall rate < 10%, episode length > 350 steps
#
# Usage:
#   uv run python training/train.py --config training/configs/ppo_standing_push.yaml
#
# Total steps = iterations × num_envs × rollout_steps
# =============================================================================
version: "0.12.2"
version_name: "Standing robustness (strong pushes)"

seed: 42

# =============================================================================
# Environment
# =============================================================================
env:
  assets_root: assets/v1

  sim_dt: 0.002
  ctrl_dt: 0.02

  max_episode_steps: 500

  # Health / termination
  target_height: 0.46
  min_height: 0.40
  max_height: 0.70
  max_pitch: 0.8
  max_roll: 0.8

  # Commands - standing only
  min_velocity: 0.0
  max_velocity: 0.0

  # Contacts
  contact_threshold_force: 5.0
  foot_switch_threshold: 2.0

  # Action filtering (alpha=0 disables filtering)
  action_filter_alpha: 0.6

  # Disturbance pushes (strong)
  push_enabled: true
  push_start_step_min: 30
  push_start_step_max: 300
  push_duration_steps: 8
  push_force_min: 3.0
  push_force_max: 7.0
  push_body: waist

# =============================================================================
# PPO Algorithm (task learning)
# =============================================================================
ppo:
  num_envs: 1024
  rollout_steps: 128
  iterations: 300

  learning_rate: 3e-4
  gamma: 0.99
  gae_lambda: 0.95

  clip_epsilon: 0.2
  entropy_coef: 0.01
  value_loss_coef: 0.5

  epochs: 4
  num_minibatches: 32
  max_grad_norm: 0.5

  log_interval: 10

# =============================================================================
# AMP (disabled for Stage 1, enabled for Stage 3)
# =============================================================================
amp:
  enabled: false

  dataset_path: null
  weight: 0.0

  discriminator:
    learning_rate: 8e-5
    batch_size: 256
    updates_per_ppo_update: 2
    r1_gamma: 10.0
    input_noise_std: 0.03

  feature_config:
    use_finite_diff_vel: true
    use_estimated_contacts: true
    mask_waist: false
    enable_mirror_augmentation: false

  targets:
    disc_acc_min: 0.55
    disc_acc_max: 0.80

# =============================================================================
# Networks (Option A: algorithm-agnostic)
# =============================================================================
networks:
  actor:
    hidden_sizes: [256, 256, 128]
    activation: elu

  critic:
    hidden_sizes: [256, 256, 128]
    activation: elu

  discriminator:
    hidden_sizes: [512, 256]
    activation: relu

# =============================================================================
# Task Reward Weights (Environment-side reward only)
# =============================================================================
reward_weights:
  tracking_lin_vel: 1.0
  lateral_velocity: -0.5
  base_height: 3.0
  orientation: -2.0
  height_target: 1.0
  height_target_sigma: 0.04
  angular_velocity: -0.1

  torque: -0.001
  saturation: -0.1
  action_rate: -0.01
  joint_velocity: -0.001

  slip: -0.5
  clearance: 0.1
  stance_width_penalty: -0.5
  stance_width_target: 0.19
  stance_width_sigma: 0.05

  forward_velocity_scale: 4.0

# =============================================================================
# Reward Composition (Trainer-side)
# =============================================================================
reward:
  task_weight: 1.0
  amp_weight: 0.0
  task_reward_clip: null
  amp_reward_clip: [0.0, 1.0]

# =============================================================================
# Checkpoints
# =============================================================================
checkpoints:
  dir: training/checkpoints
  interval: 10

# =============================================================================
# Logging
# =============================================================================
wandb:
  enabled: true
  project: wildrobot-ppo
  mode: offline
